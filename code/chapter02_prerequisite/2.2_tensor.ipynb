{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 数据操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.1 <torch._C.Generator object at 0x00000221EE8590F0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "print(torch.__version__, torch.manual_seed(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 创建`Tensor`\n",
    "\n",
    "创建一个5x3的未初始化的`Tensor`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[8.9082e-39, 5.9694e-39, 8.9082e-39],\n        [1.0194e-38, 9.1837e-39, 4.6837e-39],\n        [9.2755e-39, 1.0837e-38, 8.4490e-39],\n        [1.1112e-38, 1.0194e-38, 9.0919e-39],\n        [8.7245e-39, 1.0102e-38, 8.4490e-39]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个5x3的随机初始化的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885],\n        [0.1320, 0.3074, 0.6341],\n        [0.4901, 0.8964, 0.4556],\n        [0.6323, 0.3489, 0.4017],\n        [0.0223, 0.1689, 0.2939]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个5x3的long型全0的`Tensor`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接根据数据创建:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还可以通过现有的`Tensor`来创建，此方法会默认重用输入`Tensor`的一些属性，例如数据类型，除非自定义数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([[ 0.6035,  0.8110, -0.0451],\n        [ 0.8797,  1.0482, -0.0445],\n        [-0.7229,  2.8663, -0.5655],\n        [ 0.1604, -0.0254,  1.0739],\n        [ 2.2628, -0.9175, -0.2251]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.float64)      # 返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # 指定新的数据类型\n",
    "print(x)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过`shape`或者`size()`来获取`Tensor`的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 3])\ntorch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 操作\n",
    "### 算术操作\n",
    "* **加法形式一**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.1473, 0.5223, 0.1475],\n        [0.2248, 0.2086, 0.6709],\n        [0.2020, 0.4891, 0.5210],\n        [0.8223, 0.1220, 0.1567],\n        [0.2097, 0.8500, 0.3203]])\ntensor([[0.9217, 0.6808, 0.5633],\n        [0.4963, 0.4012, 0.5627],\n        [0.3858, 0.4965, 0.5638],\n        [0.1089, 0.2379, 0.9037],\n        [0.0942, 0.4641, 0.9946]])\ntensor([[1.0691, 1.2031, 0.7108],\n        [0.7210, 0.6098, 1.2336],\n        [0.5879, 0.9856, 1.0848],\n        [0.9312, 0.3600, 1.0605],\n        [0.3039, 1.3141, 1.3149]]) 2344831250048\ntensor([[1.0691, 1.2031, 0.7108],\n        [0.7210, 0.6098, 1.2336],\n        [0.5879, 0.9856, 1.0848],\n        [0.9312, 0.3600, 1.0605],\n        [0.3039, 1.3141, 1.3149]])\ntensor([[2.0691, 2.2031, 1.7108],\n        [1.7210, 1.6098, 2.2336],\n        [1.5879, 1.9856, 2.0848],\n        [1.9312, 1.3600, 2.0605],\n        [1.3039, 2.3141, 2.3149]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "z = x + y\n",
    "print(z, id(z))\n",
    "x += 1\n",
    "print(z)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式二**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.3967,  1.0892,  0.4369],\n        [ 1.6995,  2.0453,  0.6539],\n        [-0.1553,  3.7016, -0.3599],\n        [ 0.7536,  0.0870,  1.2274],\n        [ 2.5046, -0.1913,  0.4760]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.3967,  1.0892,  0.4369],\n        [ 1.6995,  2.0453,  0.6539],\n        [-0.1553,  3.7016, -0.3599],\n        [ 0.7536,  0.0870,  1.2274],\n        [ 2.5046, -0.1913,  0.4760]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **加法形式三、inplace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.3967,  1.0892,  0.4369],\n        [ 1.6995,  2.0453,  0.6539],\n        [-0.1553,  3.7016, -0.3599],\n        [ 0.7536,  0.0870,  1.2274],\n        [ 2.5046, -0.1913,  0.4760]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注：PyTorch操作inplace版本都有后缀\"_\", 例如`x.copy_(y), x.t_()`**\n",
    "\n",
    "### 索引\n",
    "我们还可以使用类似NumPy的索引操作来访问`Tensor`的一部分，需要注意的是：**索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.2038, 0.6511, 0.7745, 0.4369, 0.5191],\n        [0.6159, 0.8102, 0.9801, 0.1147, 0.3168],\n        [0.6965, 0.9143, 0.9351, 0.9412, 0.5995],\n        [0.0652, 0.5460, 0.1872, 0.0340, 0.9442],\n        [0.8802, 0.0012, 0.5936, 0.4158, 0.4177]])\ntensor([1.2038, 1.6511, 1.7745, 1.4369, 1.5191])\ntensor([1.2038, 1.6511, 1.7745, 1.4369, 1.5191])\ntensor([-0.3035, -0.0857, -0.0649, -0.0588, -0.4005]) tensor([[ 1.2038e+00,  1.6511e+00,  1.7745e+00,  1.4369e+00,  1.5191e+00],\n        [ 6.1585e-01,  8.1019e-01,  9.8010e-01,  1.1469e-01,  3.1677e-01],\n        [-3.0350e-01, -8.5725e-02, -6.4896e-02, -5.8822e-02, -4.0049e-01],\n        [ 6.5209e-02,  5.4600e-01,  1.8720e-01,  3.4023e-02,  9.4425e-01],\n        [ 8.8018e-01,  1.2360e-03,  5.9359e-01,  4.1577e-01,  4.1772e-01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 5)\n",
    "print(x)\n",
    "y = x[0, :]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # 源tensor也被改了\n",
    "z = x[2, :]\n",
    "z -= 1\n",
    "print(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变形状\n",
    "用`view()`来改变`Tensor`的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\ntensor([[0.2711, 0.6923, 0.2038],\n        [0.6833, 0.7529, 0.8579],\n        [0.6870, 0.0051, 0.1757],\n        [0.7497, 0.6047, 0.1100],\n        [0.2121, 0.9704, 0.8369]])\ntensor([0.2711, 0.6923, 0.2038, 0.6833, 0.7529, 0.8579, 0.6870, 0.0051, 0.1757,\n        0.7497, 0.6047, 0.1100, 0.2121, 0.9704, 0.8369])\ntensor([[0.2711, 0.6923, 0.2038, 0.6833, 0.7529],\n        [0.8579, 0.6870, 0.0051, 0.1757, 0.7497],\n        [0.6047, 0.1100, 0.2121, 0.9704, 0.8369]])\ntensor([[0.2711, 0.6923, 0.2038, 0.6833, 0.7529],\n        [0.8579, 0.6870, 0.0051, 0.1757, 0.7497],\n        [0.6047, 0.1100, 0.2121, 0.9704, 0.8369]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = x.view(15)\n",
    "z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来\n",
    "m = x.view(3, -1)\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意`view()`返回的新tensor与源tensor共享内存，也即更改其中的一个，另外一个也会跟着改变。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.3986, 0.7742, 0.7703, 0.0178, 0.8119],\n        [0.1087, 0.3943, 0.2973, 0.4037, 0.4018],\n        [0.0513, 0.0683, 0.4218, 0.5065, 0.2729],\n        [0.6883, 0.0500, 0.4663, 0.9397, 0.2961],\n        [0.9515, 0.6811, 0.0488, 0.8163, 0.4423]])\nid:  2344810515968 2344810513152\nid: 2344716438656\ntensor([[1.3986, 1.7742, 1.7703, 1.0178, 1.8119],\n        [1.1087, 1.3943, 1.2973, 1.4037, 1.4018],\n        [1.0513, 1.0683, 1.4218, 1.5065, 1.2729],\n        [1.6883, 1.0500, 1.4663, 1.9397, 1.2961],\n        [1.9515, 1.6811, 1.0488, 1.8163, 1.4423]])\ntensor([[1.3986, 1.7742, 1.7703, 1.0178, 1.8119],\n        [1.1087, 1.3943, 1.2973, 1.4037, 1.4018],\n        [1.0513, 1.0683, 1.4218, 1.5065, 1.2729],\n        [1.6883, 1.0500, 1.4663, 1.9397, 1.2961],\n        [1.9515, 1.6811, 1.0488, 1.8163, 1.4423]])\ntensor([[1.3986, 1.7742, 1.7703, 1.0178, 1.8119, 1.1087, 1.3943, 1.2973, 1.4037,\n         1.4018, 1.0513, 1.0683, 1.4218, 1.5065, 1.2729, 1.6883, 1.0500, 1.4663,\n         1.9397, 1.2961, 1.9515, 1.6811, 1.0488, 1.8163, 1.4423]])\ntensor([1.3986, 1.7742, 1.7703, 1.0178, 1.8119])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# x += 1\n",
    "# print(x)\n",
    "# print(y) # 也加了1\n",
    "\n",
    "x = torch.rand(5, 5)\n",
    "print(x)\n",
    "y = x\n",
    "z = x.view(-1, 25)\n",
    "print(\"id: \", id(x), id(z))\n",
    "m = x[0, :]\n",
    "print(\"id:\", id(m))\n",
    "x += 1\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想共享内存，推荐先用`clone`创造一个副本然后再使用`view`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "shape '[15]' is invalid for input of size 25",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-f0465ab692a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_cp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[15]' is invalid for input of size 25"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个常用的函数就是`item()`, 它可以将一个标量`Tensor`转换成一个Python number："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3466])\n",
      "2.3466382026672363\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.4 运算的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out=y) # y += x, y.add_(x)\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 `Tensor`和NumPy相互转换\n",
    "**`numpy()`和`from_numpy()`这两个函数产生的`Tensor`和NumPy array实际是使用的相同的内存，改变其中一个时另一个也会改变！！！**\n",
    "### `Tensor`转NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy数组转`Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接用`torch.tensor()`将NumPy数组转换成`Tensor`，该方法总是会进行数据拷贝，返回的`Tensor`和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 用torch.tensor()转换时不会共享内存\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.6 `Tensor` on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2344830634688\ntensor([[2.1473, 2.5223, 2.1475],\n        [2.2248, 2.2086, 2.6709],\n        [2.2020, 2.4891, 2.5210],\n        [2.8223, 2.1220, 2.1567],\n        [2.2097, 2.8500, 2.3203]])\n2344830634688\n"
     ]
    }
   ],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(id(z))\n",
    "    print(z.to(\"cpu\"))       # to()还可以同时更改数据类型\n",
    "    print(id(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd0dca4efdd400e53e6663797bbd1b46cf726b4dffb9a4cd6e80b88fc0d122f2781",
   "display_name": "Python 3.8.10 64-bit ('pytorch_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "dca4efdd400e53e6663797bbd1b46cf726b4dffb9a4cd6e80b88fc0d122f2781"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}